# ğŸ¤– Discord RAG Bot - AI Bootcamp Project

A production-ready Discord bot using Retrieval-Augmented Generation (RAG) to answer questions about the AI Bootcamp documentation.

## ğŸ¯ Project Overview

**Role:** Data Scientist  
**Tech Stack:** 100% Local & Free (No Credit Cards!)

- **Vector DB:** ChromaDB (local, in-memory)
- **Embeddings:** SentenceTransformers (all-MiniLM-L6-v2)
- **LLM:** Ollama (llama3.2:3b - runs locally)
- **Bot Framework:** Discord.py
- **Package Manager:** uv (fast Python package installer)

## ğŸ“ Project Structure

```
discord-rag-bot/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ discord_rag_bot/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ bot.py                    # ğŸ¤– Discord bot entry point
â”‚       â”‚
â”‚       â”œâ”€â”€ core/                     # ğŸ§  Core RAG logic
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ rag_engine.py         # Main RAG orchestrator
â”‚       â”‚   â””â”€â”€ knowledge_base.py     # KB management (user KBs)
â”‚       â”‚
â”‚       â”œâ”€â”€ processing/               # ğŸ“„ Document processing
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ converters.py         # PDF/DOCX/TXT â†’ text
â”‚       â”‚   â”œâ”€â”€ chunkers.py           # Smart text chunking
â”‚       â”‚   â””â”€â”€ validators.py         # File validation
â”‚       â”‚
â”‚       â”œâ”€â”€ embeddings/               # ğŸ”¢ Vector embeddings
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ embedding_service.py  # Embedding generation
â”‚       â”‚
â”‚       â”œâ”€â”€ retrieval/                # ğŸ” Search & retrieval
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ retriever.py          # Vector search logic
â”‚       â”‚
â”‚       â”œâ”€â”€ generation/               # ğŸ’¬ Answer generation
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ generator.py          # LLM integration (Ollama)
â”‚       â”‚
â”‚       â”œâ”€â”€ storage/                  # ğŸ’¾ Data persistence
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ vector_store.py       # ChromaDB manager
â”‚       â”‚   â””â”€â”€ memory_store.py       # MongoDB for chat history
â”‚       â”‚
â”‚       â”œâ”€â”€ commands/                 # ğŸ® Discord commands
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ upload.py             # Upload files command
â”‚       â”‚   â”œâ”€â”€ ask.py                # Ask questions command
â”‚       â”‚   â”œâ”€â”€ list_kb.py            # List knowledge bases
â”‚       â”‚   â””â”€â”€ delete_kb.py          # Delete knowledge base
â”‚       â”‚
â”‚       â””â”€â”€ utils/                    # ğŸ› ï¸ Utilities
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ helpers.py            # Helper functions
â”‚           â””â”€â”€ config.py             # Configuration
â”‚
â”œâ”€â”€ data/                             # ğŸ“ Data storage
â”‚   â”œâ”€â”€ uploads/                      # Temporary file uploads
â”‚   â”œâ”€â”€ chromadb/                     # Vector DB persistence
â”‚   â””â”€â”€ logs/                         # Application logs
â”‚
â”œâ”€â”€ tests/                            # ğŸ§ª Tests
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env                              # ğŸ” Environment variables
â”œâ”€â”€ pyproject.toml                    # ğŸ“¦ Dependencies
â””â”€â”€ README.md                         # ğŸ“– Documentation
```

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.12+** installed
2. **uv** package manager:
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

3. **Ollama** (local LLM):
   ```bash
   # macOS
   brew install ollama
   
   # Start Ollama service
   ollama serve
   
   # In another terminal, pull the model (3.2GB download)
   ollama pull llama3.2:3b
   ```

### Installation

```bash
# 1. Clone/enter project directory
cd discord-rag-bot

# 2. Install dependencies
uv sync

# 3. Activate virtual environment
source .venv/bin/activate  # macOS/Linux
```
